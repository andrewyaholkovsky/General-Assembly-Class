# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Kaggle Challenge: Classification

## Introduction

Welcome to your first week of work at the Center for Disease Control. Time to get to work!

Due to the recent epidemic of West Nile Virus in the Windy City, we've had Chicago's Department of Public Health set up a surveillance and control system. We're hoping it will let us learn something from the mosquito population as we collect data over time. Pesticides are a necessary evil in the fight for public health and safety, not to mention expensive. We need to derive an effective plan to deploy pesticides throughout the city, and that is **exactly** where you come in.

You and your team will need to help us track and predict the regions with the highest concentration of viral mosquito vectors. Also, see Cathy in HR about getting your benefits set up. We have a GREAT health plan!

Once again, welcome to the CDC. We have high expectations for you!

---

## Dataset

The dataset, along with description, can be found here: [https://www.kaggle.com/c/predict-west-nile-virus/](https://www.kaggle.com/c/predict-west-nile-virus/).

**This is also where you will be submitting your code for evaluation**. We will be using the Kaggle Leaderboard to keep track of your score. The leaderboard uses roughly 30% of the dataset to score an AUC (Area Under Curve) metric. [You can read more about the scoring metric here](https://www.kaggle.com/c/predict-west-nile-virus#evaluation). Despite the fact that an official Kaggle competition is closed, teams can still submit their models and get evaluated by their official metrics, which allows for us to use these competitions even though they are "over".

---

## Requirements

Here is your team's assignment:
- Create a Jupyter notebook
- Investigate the data and develop features
- Fit and score multiple classification models
- Submit notebook for automated Kaggle scoring
- Create a presentation of your findings

---

## Evaluation

Your Kaggle submission will be evaluated in the following 2 areas:

1. **AUC Score**: A clear winning group will be determined based on the AUC Scoring performed by the Kaggle Leaderboard. This is not to say that the winning group's work will always be the best submission. A standout project will also have:

4. **Brief Presentation**: Your presentation should be short and sweet.  Describe your data and approach as if your client is in front of you. Explain the features you used, models you evaluated, which features proved to be key predictors, the metric you used to evaluate, and include visualizations of your results. Assume you have more time and convey next steps to advance your findings.

---

## Suggested Ways to Get Started

#### EDA

1. Ask questions to describe the data. What does it represent? What types are present? What does each data points' distribution look like?
2. What kind of cleaning is needed? Document any potential issues that will need to be resolved.
3. When describing your approach, try following the scientific method. Ask: What is our problem statement? What can we learn from the data in order to make an educated hypothesis? What is our hypothesis?

#### Project Planning

1. Define your deliverable: what is the end result?
2. Break that deliverable up into its components, and then divide further until you have actionable items.
3. Begin deciding priorities and owners for each task. 

---
