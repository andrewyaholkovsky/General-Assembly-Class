{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Visualizing CARTs with admissions data\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "Using the admissions data from earlier in the course, build CARTs, look at how they work visually, and compare their performance to more standard, parametric models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Load in admissions data and other python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "admit = pd.read_csv('../../data/admissions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Create regression and classification X, y data\n",
    "\n",
    "The regression data will be:\n",
    "\n",
    "    Xr = [admit, gre, prestige]\n",
    "    yr = gpa\n",
    "    \n",
    "The classification data will be:\n",
    "\n",
    "    Xc = [gre, gpa, prestige]\n",
    "    yc = admit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "admit = admit.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige\n",
       "0      0  380.0  3.61       3.0\n",
       "1      1  660.0  3.67       3.0\n",
       "2      1  800.0  4.00       1.0\n",
       "3      1  640.0  3.19       4.0\n",
       "4      0  520.0  2.93       4.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr = admit[['admit','gre','prestige']]\n",
    "yr = admit.gpa\n",
    "\n",
    "Xc = admit[['gpa','gre','prestige']]\n",
    "yc = admit.admit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Cross-validate regression and logistic regression on the data\n",
    "\n",
    "Fit a linear regression for the regression problem and a logistic for the classification problem. Cross-validate the R2 and accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22470964 0.08296819 0.03204903 0.16434809] 0.12601873539032846\n",
      "[0.71       0.72727273 0.68686869 0.70707071] 0.7078030303030304\n"
     ]
    }
   ],
   "source": [
    "reg_scores = cross_val_score(LinearRegression(), Xr, yr, cv=4)\n",
    "cls_scores = cross_val_score(LogisticRegression(), Xc, yc, cv=4)\n",
    "\n",
    "print (reg_scores, np.mean(reg_scores))\n",
    "print (cls_scores, np.mean(cls_scores))\n",
    "\n",
    "linreg = LinearRegression().fit(Xr, yr)\n",
    "logreg = LogisticRegression().fit(Xc, yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Building regression trees\n",
    "\n",
    "With `DecisionTreeRegressor`:\n",
    "\n",
    "1. Build 4 models with different parameters for `max_depth`: `max_depth=1`, `max_depth=2`, `max_depth=3`, and `max_depth=None`\n",
    "2. Cross-validate the R2 scores of each of the models and compare to the linear regression earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr1 = DecisionTreeRegressor(max_depth=1)\n",
    "dtr2 = DecisionTreeRegressor(max_depth=2)\n",
    "dtr3 = DecisionTreeRegressor(max_depth=3)\n",
    "dtrN = DecisionTreeRegressor(max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr1.fit(Xr, yr)\n",
    "dtr2.fit(Xr, yr)\n",
    "dtr3.fit(Xr, yr)\n",
    "dtrN.fit(Xr, yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16618105 0.1535036  0.03860296 0.10081223] 0.1147749611042107\n",
      "[0.20722899 0.14179888 0.04112242 0.11836674] 0.1271292579858377\n",
      "[0.15422529 0.123802   0.05252648 0.08070045] 0.10281355747790263\n",
      "[-0.14933234 -0.15835462 -0.4649248  -0.17945056] -0.23801557770560355\n"
     ]
    }
   ],
   "source": [
    "dtr1_scores = cross_val_score(dtr1, Xr, yr, cv=4)\n",
    "dtr2_scores = cross_val_score(dtr2, Xr, yr, cv=4)\n",
    "dtr3_scores = cross_val_score(dtr3, Xr, yr, cv=4)\n",
    "dtrN_scores = cross_val_score(dtrN, Xr, yr, cv=4)\n",
    "\n",
    "print (dtr1_scores, np.mean(dtr1_scores))\n",
    "print (dtr2_scores, np.mean(dtr2_scores))\n",
    "print (dtr3_scores, np.mean(dtr3_scores))\n",
    "print (dtrN_scores, np.mean(dtrN_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Building classification trees\n",
    "\n",
    "With `DecisionTreeClassifier`:\n",
    "\n",
    "1. Again build 4 models with different parameters for `max_depth`: `max_depth=1`, `max_depth=2`, `max_depth=3`, and `max_depth=None`\n",
    "2. Cross-validate the accuracy scores of each of the models and compare to the logistic regression earlier.\n",
    "\n",
    "Note that now you'll be using the classification task where we are predicting `admit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc1 = DecisionTreeClassifier(max_depth=1)\n",
    "dtc2 = DecisionTreeClassifier(max_depth=2)\n",
    "dtc3 = DecisionTreeClassifier(max_depth=3)\n",
    "dtcN = DecisionTreeClassifier(max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc1.fit(Xc, yc)\n",
    "dtc2.fit(Xc, yc)\n",
    "dtc3.fit(Xc, yc)\n",
    "dtcN.fit(Xc, yc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68       0.68686869 0.66666667 0.67676768] 0.6775757575757576\n",
      "[0.69       0.76767677 0.63636364 0.61616162] 0.6775505050505051\n",
      "[0.77       0.76767677 0.61616162 0.6969697 ] 0.7127020202020202\n",
      "[0.62       0.67676768 0.58585859 0.56565657] 0.6120707070707071\n"
     ]
    }
   ],
   "source": [
    "dtc1_scores = cross_val_score(dtc1, Xc, yc, cv=4)\n",
    "dtc2_scores = cross_val_score(dtc2, Xc, yc, cv=4)\n",
    "dtc3_scores = cross_val_score(dtc3, Xc, yc, cv=4)\n",
    "dtcN_scores = cross_val_score(dtcN, Xc, yc, cv=4)\n",
    "\n",
    "print (dtc1_scores, np.mean(dtc1_scores))\n",
    "print (dtc2_scores, np.mean(dtc2_scores))\n",
    "print (dtc3_scores, np.mean(dtc3_scores))\n",
    "print (dtcN_scores, np.mean(dtcN_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Print out the \"feature importances\"\n",
    "\n",
    "The model has an attribute called `.feature_importances_` which can tell us which features were most important vs. others. It ranges from 0 to 1, with 1 being the most important.\n",
    "\n",
    "An easy way to think about the feature importance is how much that particular variable was used to make decisions. Really though, it also takes into account how much that feature contributed to splitting up the class or reducing the variance.\n",
    "\n",
    "A feature with higher feature importance reduced the criterion (impurity) more than the other features.\n",
    "\n",
    "Below, show the feature importances for each variable predicting private vs. not, sorted by most important feature to least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prestige</td>\n",
       "      <td>0.402035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpa</td>\n",
       "      <td>0.355654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gre</td>\n",
       "      <td>0.242311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "2  prestige    0.402035\n",
       "0       gpa    0.355654\n",
       "1       gre    0.242311"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':Xc.columns,\n",
    "        'importance':dtc3.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
