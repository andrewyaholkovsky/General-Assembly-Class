{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Train-test Split and Cross-Validation Lab\n",
    "\n",
    "_Authors: Joseph Nelson (DC), Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "## Review of train/test validation methods\n",
    "\n",
    "We've discussed overfitting, underfitting, and how to validate the \"generalizeability\" of your models by testing them on unseen data. \n",
    "\n",
    "In this lab you'll practice two related validation methods: \n",
    "1. **train/test split**\n",
    "2. **k-fold cross-validation**\n",
    "\n",
    "Train/test split and k-fold cross-validation both serve two useful purposes:\n",
    "- We prevent overfitting by not using all the data, and\n",
    "- We retain some remaining data to evaluate our model.\n",
    "\n",
    "In the case of cross-validation, the model fitting and evaluation is performed multiple times on different train/test splits of the data.\n",
    "\n",
    "Ultimately we can the training and testing validation framework to compare multiple models on the same dataset. This could be comparisons of two linear models, or of completely different models on the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean up any data problems\n",
    "\n",
    "Load the Boston housing data.  Fix any problems, if applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boston data is from SKlearn so it is clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a null baseline score by comparing the observed target values to each average target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.188011545278203"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import mse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# get an array of average values of boston.target the same length as boston.target\n",
    "target_mean_list = [boston.target.mean() for x in boston.target]\n",
    "# passing the boston.target values and target_mean_list values into the mean squared error function and take \n",
    "# the square root\n",
    "np.sqrt(mean_squared_error(boston.target, target_mean_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select 3-4 variables with your dataset to perform a 70/30 test train split on\n",
    "\n",
    "- Use sklearn.\n",
    "- Score and plot your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2c60be9a677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'CRIM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'RM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LSTAT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "predictors = ['CRIM', u'RM', 'B', 'LSTAT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[predictors], y, train_size=0.7, random_state=8)\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lr.predict(X_test)\n",
    "sns.jointplot(x=y_test, y=yhat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Interpret your coefficients using the coef_ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.077744</td>\n",
       "      <td>5.399703</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>-0.584165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        RM         B     LSTAT\n",
       "0 -0.077744  5.399703  0.010551 -0.584165"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for every 1 unit increase in RM, prediction increases by 5.4\n",
    "# for every 1 unit increase in CRIM, prediction decreases by -0.07...\n",
    "pd.DataFrame(lr.coef_,predictors).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Standardize your training split and fit a regression on it,  compute the rmse on your testing split, and analyze your features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.583126677986091\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.716997</td>\n",
       "      <td>3.625816</td>\n",
       "      <td>1.002232</td>\n",
       "      <td>-4.131158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        RM         B     LSTAT\n",
       "0 -0.716997  3.625816  1.002232 -4.131158"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# instantiate scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# standardize numeric features in training data\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "\n",
    "# instantiate estimator\n",
    "lr = LinearRegression()\n",
    "\n",
    "# fit regression on training data\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# standardize numeric features in test data\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "# make predictions\n",
    "y_preds = lr.predict(X_test_scaled)\n",
    "\n",
    "# score predictions\n",
    "print(np.sqrt(mean_squared_error(y_test, y_preds)))\n",
    "\n",
    "# analyze \n",
    "# for every 1 standard deviation increase in RM, prediction increases by 3.6\n",
    "# for every 1 standard deviation increase in CRIM, prediction decreases by -0.71...\n",
    "pd.DataFrame(lr.coef_,predictors).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Try K-Folds cross-validation with a K of 5 on your training split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def run_cv(estimator):\n",
    "    \n",
    "    # pass estimator, predictor matrix, target variable, scoring function, number of folds into function\n",
    "    scores = cross_validate(estimator, X_train_scaled, y_train, scoring='neg_mean_squared_error',cv=5, \n",
    "                            return_train_score=False)\n",
    "\n",
    "    # looking at the spread of the individual error values gives us a sense of our variance - score here are erratic\n",
    "    print(np.sqrt(abs(scores['test_score'])))\n",
    "\n",
    "    # looking at the average error across folds points to the average error for a prediction\n",
    "    print(np.mean(np.sqrt(abs(scores['test_score']))))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.28969877 5.63830346 6.28396516 5.83071032 4.20550099]\n",
      "5.449635736544363\n"
     ]
    }
   ],
   "source": [
    "# with linear regression\n",
    "lr = LinearRegression()\n",
    "run_cv(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.10681781 3.35909987 4.30042699 4.56127875 3.76659114]\n",
      "4.018842910848226\n"
     ]
    }
   ],
   "source": [
    "# use cross validation to compare output to another estimator\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()\n",
    "run_cv(rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what to do after training best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098134</td>\n",
       "      <td>0.305222</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>0.567585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        RM         B     LSTAT\n",
       "0  0.098134  0.305222  0.029059  0.567585"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after cv, fit regression on training data\n",
    "rfr.fit(X_train_scaled, y_train)\n",
    "# analyze what's driving predictions - can't get this from cross validation\n",
    "pd.DataFrame(rfr.feature_importances_,predictors).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.262101013893451\n"
     ]
    }
   ],
   "source": [
    "# analyze your model's testing error\n",
    "\n",
    "# make predictions\n",
    "y_preds = rfr.predict(X_test_scaled)\n",
    "\n",
    "# score predictions\n",
    "print(np.sqrt(mean_squared_error(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.175, 15.698, 48.797, 26.642, 47.627, 21.835, 14.744, 31.188,\n",
       "       24.06 , 38.768, 16.295, 12.366, 20.634, 21.472, 15.944, 30.46 ,\n",
       "       21.502, 20.674, 19.224,  5.819, 21.114, 24.257, 28.56 , 37.942,\n",
       "       26.167, 35.528,  8.476, 16.151, 21.437, 16.271, 29.11 , 14.463,\n",
       "       18.186, 20.643, 28.609, 32.103, 36.524, 23.2  , 17.462, 11.908,\n",
       "       18.719, 23.235, 45.066, 31.135, 29.518, 18.626, 14.156, 20.637,\n",
       "       19.631, 20.711, 20.572, 10.929, 28.723, 13.734, 17.668, 24.915,\n",
       "       19.872,  9.23 , 20.571, 30.581, 23.362, 25.044, 19.264,  9.03 ,\n",
       "       16.458, 23.933, 10.239, 20.761, 28.723, 43.994, 18.296, 22.534,\n",
       "       25.144, 30.841, 19.156, 23.844, 27.303, 22.104, 17.165, 16.081,\n",
       "       16.69 ,  8.863, 14.981, 20.893, 20.727, 27.388, 14.896, 16.953,\n",
       "       24.939, 33.757, 20.414, 20.424, 30.98 , 43.482, 15.918, 35.22 ,\n",
       "       20.781, 24.037, 21.819, 13.095,  9.568, 27.816,  8.733, 47.495,\n",
       "       30.515, 21.952, 15.654, 21.216, 24.708, 21.129, 18.502, 20.837,\n",
       "       46.17 , 11.401, 21.087, 19.74 , 41.803, 17.882, 20.834, 20.698,\n",
       "       28.958, 27.044, 14.084, 23.861, 23.209, 16.954, 20.533, 28.225,\n",
       "       45.593,  7.865, 20.922, 48.825, 27.548, 25.853, 21.091, 15.622,\n",
       "       16.681, 20.179, 21.731, 20.437, 23.694, 26.558, 24.18 , 26.44 ,\n",
       "       33.564, 21.113, 17.818, 18.037, 24.648, 20.303, 16.08 , 25.597])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we could save best model and use it again later\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "dump(rfr, 'rfr_boston_crim_rm_b_lstat.joblib')\n",
    "rfr = load('rfr_boston_crim_rm_b_lstat.joblib')\n",
    "rfr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**or we could move back in the process and see if we can improve our results**\n",
    "* by adding/deriving features\n",
    "* adding more data\n",
    "* trying more estimators\n",
    "* tuning hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
