{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Train/Test Split and Bias and Variance\n",
    "\n",
    "_Authors: Joseph Nelson (DC), Kevin Markham (DC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "<a id=\"learning-objectives\"></a>\n",
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "\n",
    "- Explain problems associated with over- and underfitting.\n",
    "- Grasp why train/test split is necessary.\n",
    "- Explore k-folds, LOOCV, and three split methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "\n",
    "- [Train/Test Split](#train-test-split)\n",
    "\t- [Evaluation Procedure #1: Train and Test on the Entire Data Set (Do Not Do This)](#evaluation-procedure--train-and-test-on-the-entire-dataset-do-not-do-this)\n",
    "\t- [Problems With Training and Testing on the Same Data](#problems-with-training-and-testing-on-the-same-data)\n",
    "\t- [Evaluation Procedure #2: Train/Test Split](#evaluation-procedure--traintest-split)\n",
    "\t- [Comparing Test Performance With a Null Baseline](#comparing-test-performance-with-a-null-baseline)\n",
    "- [K-Folds Cross-Validation](#k-folds-cross-validation)\n",
    "\t- [Leave-One-Out Cross-Validation](#leave-one-out-cross-validation)\n",
    "\t- [Intro to Cross-Validation With the Boston Data](#intro-to-cross-validation-with-the-boston-data)\n",
    "- [Three-Way Data Split](#three-way-data-split)\n",
    "\t- [Additional Resources](#additional-resources)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Allow plots to appear in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"train-test-split\"></a>\n",
    "## Train-test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the lab, we will look at three evaluation procedures for predicting model out-of-sample accuracy:\n",
    "\n",
    "1. **Train on the entire dataset** should never be done to estimate model accuracy on out-of-sample data! After all, training error can be made arbitrarily small or large. You might train on the entire dataset as the very last step when a model is chosen, hoping to make the final model as accurate as possible. Or, you could use this to estimate the degree of overfitting.\n",
    "2. **Train-test-split** is useful if cross-validation is not practical (e.g. it takes too long to train). It is also useful for computing a quick confusion matrix. You could also use this as a final step after the model is finalized (often called evaluating the model against a **validation set**).\n",
    "3. **Cross-validation** is the gold standard for estimating accuracy and comparing accuracy across models.\n",
    "4. **Three-way split** combines cross-validation and the train-test-split. It takes an initial split to be used as a final validation set, then uses cross-validation on the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run into a problem when powerful models can perfectly fit the data on which they are trained. However, we can't observe the variance of a model directly, because we only know how it fits the data we have rather than all potential samples.\n",
    "\n",
    "**Solution:** Create a procedure that **estimates** how well a model is likely to perform on out-of-sample data and use that to choose between models.\n",
    "\n",
    "- Before, we have been splitting the data into a **single training group** and a **single test group**.\n",
    "\n",
    "- Now, to estimate how well the model is likely to perform on out-of-sample data, we will create **many training groups** and **many test groups** then fit **many models**.\n",
    "\n",
    "**Note:** These procedures can be used with **any machine learning model**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**The Holdout Method: Train/Test Split**\n",
    "- **Training set**: Used to train the classifier.\n",
    "- **Testing set**: Used to estimate the error rate of the trained classifier.\n",
    "- **Advantages**: Fast, simple, computationally inexpensive.\n",
    "- **Disadvantages** Eliminates data, imperfectly splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"evaluation-procedure--train-and-test-on-the-entire-dataset-do-not-do-this\"></a>\n",
    "### Evaluation Procedure #1: Train and Test on the Entire Data Set (Do Not Do This)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Train the model on the **entire data set**.\n",
    "2. Test the model on the **same data set** and evaluate how well we did by comparing the **predicted** response values with the **true** response values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the Boston data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create X and y variable to stores the feature matrix and response from the Boston data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for both parts of data; don't forget to assign column names.\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns=['MEDV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate y and X, then overwrite the Boston variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.concat([y, X], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform basic EDA to make sure the data are in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEDV       0\n",
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEDV       float64\n",
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS       float64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD        float64\n",
       "TAX        float64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MEDV</th>\n",
       "      <td>506.0</td>\n",
       "      <td>22.532806</td>\n",
       "      <td>9.197104</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>21.20000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>506.0</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.25651</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>506.0</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>506.0</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>9.69000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>506.0</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>506.0</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>506.0</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>6.20850</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>8.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>506.0</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.90000</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>77.50000</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>506.0</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>1.12960</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>3.20745</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>506.0</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>506.0</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>187.00000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>330.00000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>711.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>506.0</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>19.05000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>22.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>506.0</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>391.44000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>396.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>506.0</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>1.73000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>11.36000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>37.9700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std        min         25%        50%  \\\n",
       "MEDV     506.0   22.532806    9.197104    5.00000   17.025000   21.20000   \n",
       "CRIM     506.0    3.613524    8.601545    0.00632    0.082045    0.25651   \n",
       "ZN       506.0   11.363636   23.322453    0.00000    0.000000    0.00000   \n",
       "INDUS    506.0   11.136779    6.860353    0.46000    5.190000    9.69000   \n",
       "CHAS     506.0    0.069170    0.253994    0.00000    0.000000    0.00000   \n",
       "NOX      506.0    0.554695    0.115878    0.38500    0.449000    0.53800   \n",
       "RM       506.0    6.284634    0.702617    3.56100    5.885500    6.20850   \n",
       "AGE      506.0   68.574901   28.148861    2.90000   45.025000   77.50000   \n",
       "DIS      506.0    3.795043    2.105710    1.12960    2.100175    3.20745   \n",
       "RAD      506.0    9.549407    8.707259    1.00000    4.000000    5.00000   \n",
       "TAX      506.0  408.237154  168.537116  187.00000  279.000000  330.00000   \n",
       "PTRATIO  506.0   18.455534    2.164946   12.60000   17.400000   19.05000   \n",
       "B        506.0  356.674032   91.294864    0.32000  375.377500  391.44000   \n",
       "LSTAT    506.0   12.653063    7.141062    1.73000    6.950000   11.36000   \n",
       "\n",
       "                75%       max  \n",
       "MEDV      25.000000   50.0000  \n",
       "CRIM       3.677083   88.9762  \n",
       "ZN        12.500000  100.0000  \n",
       "INDUS     18.100000   27.7400  \n",
       "CHAS       0.000000    1.0000  \n",
       "NOX        0.624000    0.8710  \n",
       "RM         6.623500    8.7800  \n",
       "AGE       94.075000  100.0000  \n",
       "DIS        5.188425   12.1265  \n",
       "RAD       24.000000   24.0000  \n",
       "TAX      666.000000  711.0000  \n",
       "PTRATIO   20.200000   22.0000  \n",
       "B        396.225000  396.9000  \n",
       "LSTAT     16.955000   37.9700  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a feature matrix (X) and response (y)  for scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature matrix (X)\n",
    "feature_cols = boston.columns.drop(['MEDV'])\n",
    "X = boston[feature_cols]\n",
    "\n",
    "# create response vector (y)\n",
    "y = boston.MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import linear regression, instantiate, fit, and preview predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.00384338, 25.02556238, 30.56759672, 28.60703649, 27.94352423])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the class.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instantiate the model.\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train the model on the entire data set.\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predict the response values for the observations in X (\"test the model\"). (First five predictions shown here.)\n",
    "lr.predict(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the predicted response values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To evaluate a model, we also need an **evaluation metric:**\n",
    "\n",
    "- A numeric calculation used to **quantify** the performance of a model.\n",
    "- The appropriate metric depends on the **goals** of your problem.\n",
    "\n",
    "The most common choices for regression problems are:\n",
    "\n",
    "- **R-squared**: The percentage of variation explained by the model (a \"reward function,\" as higher is better).\n",
    "- **Mean squared error**: The average squared distance between the prediction and the correct answer (a \"loss function,\" as lower is better).\n",
    "\n",
    "In this case, we'll use mean squared error because it is more interpretable in a predictive context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute mean squared error using a function from `metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.679191295697281\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(np.sqrt(metrics.mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is known as the **training mean squared error** because we are evaluating the model based on the same data we used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"problems-with-training-and-testing-on-the-same-data\"></a>\n",
    "### Problems With Training and Testing on the Same Data\n",
    "\n",
    "- Our goal is to estimate likely performance of a model on **out-of-sample data**.\n",
    "- But, maximizing the training mean squared error rewards **overly complex models** that won't necessarily generalize.\n",
    "- Unnecessarily complex models **overfit** the training data.\n",
    "    - They will do well when tested using the in-sample data.\n",
    "    - They may do poorly with out-of-sample data.\n",
    "    - They learn the \"noise\" in the data rather than the \"signal.\"\n",
    "    - From Quora: [What is an intuitive explanation of overfitting?](http://www.quora.com/What-is-an-intuitive-explanation-of-overfitting/answer/Jessica-Su)\n",
    "\n",
    "**Thus, the training MSE is not a good estimate of the out-of-sample MSE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation-procedure--traintest-split\"></a>\n",
    "### Evaluation procedure #2: Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Split the data set into two pieces: a **training set** and a **testing set**.\n",
    "2. Train the model on the **training set**.\n",
    "3. Test the model on the **testing set** and evaluate how well we did.\n",
    "\n",
    "Often a good rule-of-thumb is 70% training/30% test, but this can vary based on the size of your dataset. For example, with a small dataset you would need to use as much training data as possible (in return, your test accuracy will be more variable).\n",
    "\n",
    "What does this accomplish?\n",
    "\n",
    "- Models can be trained and tested on **different data** (We treat testing data like out-of-sample data).\n",
    "- Response values are known for the testing set and thus **predictions can be evaluated**.\n",
    "\n",
    "This is known as the **testing mean squared error** because we are evaluating the model on an independent \"test set\" that was not used during model training.\n",
    "\n",
    "**The testing MSE is a better estimate of out-of-sample performance than the training MSE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Step 1: Split the data into a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.52014</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>8.398</td>\n",
       "      <td>91.5</td>\n",
       "      <td>2.2885</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>386.86</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "262  0.52014  20.0   3.97   0.0  0.647  8.398  91.5  2.2885  5.0  264.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "262     13.0  386.86   5.91  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# WITHOUT a random_state parameter:\n",
    "#  (If you run this code several times, you get different results!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Print the first element of each object.\n",
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(379, 13)\n",
      "(127, 13)\n"
     ]
    }
   ],
   "source": [
    "# Before splitting\n",
    "print(X.shape)\n",
    "\n",
    "# After splitting\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n",
      "(379,)\n",
      "(127,)\n"
     ]
    }
   ],
   "source": [
    "# Recall that (1,) is a tuple. \n",
    "# The trailing comma distinguishes it as being a tuple, not an integer.\n",
    "\n",
    "# Before splitting\n",
    "print(y.shape)\n",
    "\n",
    "# After splitting\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Understanding the `random_state` Parameter\n",
    "\n",
    "The `random_state` is a pseudo-random number that allows us to reproduce our results every time we run them. However, it makes it impossible to predict what are exact results will be if we chose a new `random_state`.\n",
    "\n",
    "`random_state` is very useful for testing that your model was made correctly since it provides you with the same split each time. However, make sure you remove it if you are testing for model variability!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRIM   ZN  INDUS  CHAS    NOX    RM   AGE     DIS  RAD    TAX  \\\n",
      "502  0.04527  0.0  11.93   0.0  0.573  6.12  76.7  2.2875  1.0  273.0   \n",
      "\n",
      "     PTRATIO      B  LSTAT  \n",
      "502     21.0  396.9   9.08  \n",
      "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "307  0.04932  33.0   2.18   0.0  0.472  6.849  70.3  3.1827  7.0  222.0   \n",
      "\n",
      "     PTRATIO      B  LSTAT  \n",
      "307     18.4  396.9   7.53  \n",
      "502    20.6\n",
      "Name: MEDV, dtype: float64\n",
      "307    28.2\n",
      "Name: MEDV, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# WITH a random_state parameter:\n",
    "#  (Same split every time! Note you can change the random state to any integer.)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Print the first element of each object.\n",
    "print(X_train.head(1))\n",
    "print(X_test.head(1))\n",
    "print(y_train.head(1))\n",
    "print(y_test.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train_test_split](./assets/train_test_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Train the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Test the model on the testing set and check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.74109521333182\n",
      "4.679504823808768\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# testing error\n",
    "print(np.sqrt(metrics.mean_squared_error(y_train, lr.predict(X_train))))\n",
    "# training error\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try adding new variables and repeating steps 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Training error**: Decreases as model complexity increases (lower value of k).\n",
    "- **Testing error**: Is minimized at the optimum model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-test-performance-with-a-null-baseline\"></a>\n",
    "### Comparing Test Performance With a Null Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "When interpreting the predictive power of a model, it's best to compare it to a baseline using a dummy model, sometimes called a ZeroR model or a baseline model. A dummy model is simply using the mean, median, or most common value as the prediction. This forms a benchmark to compare your model against and becomes especially important in classification where your null accuracy might be 95 percent.\n",
    "\n",
    "For example, suppose your dataset is **imbalanced** -- it contains 99% one class and 1% the other class. Then, your baseline accuracy (always guessing the first class) would be 99%. So, if your model is less than 99% accurate, you know it is worse than the baseline. Imbalanced datasets generally must be trained differently (with less of a focus on accuracy) because of this.\n",
    "\n",
    "You can alternatively use simple models to achieve baseline results, for example nearest neighbors or a basic unigram bag of words for text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the baseline mean squared error using a null model.\n",
    "How does this compare to what we achieved with linear regression. Is our model making an actual improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.952812344103908\n"
     ]
    }
   ],
   "source": [
    "# Use .apply() to broadcast a mean for every prediction.\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_test.map(lambda x: y_test.mean()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307    23.094488\n",
       "343    23.094488\n",
       "47     23.094488\n",
       "67     23.094488\n",
       "362    23.094488\n",
       "         ...    \n",
       "41     23.094488\n",
       "361    23.094488\n",
       "289    23.094488\n",
       "498    23.094488\n",
       "293    23.094488\n",
       "Name: MEDV, Length: 127, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.map(lambda x: y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"k-folds-cross-validation\"></a>\n",
    "## K-Folds Cross-Validation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train/test split provides us with helpful tool, but it's a shame that we are tossing out a large chunk of our data for testing purposes.\n",
    "\n",
    "**How can we use the maximum amount of our data points while still ensuring model integrity?**\n",
    "\n",
    "1. Split our data into a number of different pieces (folds).\n",
    "2. Train using `k-1` folds for training and a different fold for testing.\n",
    "3. Average our model against EACH of those iterations.\n",
    "4. Choose our model and TEST it against the final fold.\n",
    "5. Average all test accuracies to get the estimated out-of-sample accuracy.\n",
    "\n",
    "Although this may sound complicated, we are just training the model on k separate train-test-splits, then taking the average of the resulting test accuracies!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"leave-one-out-cross-validation\"></a>\n",
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A special case of k-fold cross-validation is leave-one-out cross-validation. Rather than taking 5–10 folds, we take a fold of size `n-1` and leave one observation to test. \n",
    "\n",
    "Typically, 5–10 fold cross-validaiton is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro-to-cross-validation-with-the-boston-data\"></a>\n",
    "### Intro to Cross-Validation With the Boston Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~ CROSS VALIDATION each fold ~~~~\n",
      "Model 1\n",
      "MSE: 3.6063150977243312\n",
      "R2: 0.7386065330077268\n",
      "\n",
      "Model 2\n",
      "MSE: 6.009617199035556\n",
      "R2: 0.7374510173464559\n",
      "\n",
      "Model 3\n",
      "MSE: 4.835520571224613\n",
      "R2: 0.7387099545038194\n",
      "\n",
      "Model 4\n",
      "MSE: 4.967488509123905\n",
      "R2: 0.7374805756730984\n",
      "\n",
      "Model 5\n",
      "MSE: 4.702828883305669\n",
      "R2: 0.737881292030066\n",
      "\n",
      "~~~~ SUMMARY OF CROSS VALIDATION ~~~~\n",
      "Mean of MSE for all folds: 4.824354052082815\n",
      "Mean of R2 for all folds: 0.7380258745122332\n"
     ]
    }
   ],
   "source": [
    "# note: this is an explicit demonstration of the steps to cross validate and *not a pracitical way* of doing cross \n",
    "# validation relative to \n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True)\n",
    "mse_values = []\n",
    "scores = []\n",
    "n = 0\n",
    "\n",
    "print(\"~~~~ CROSS VALIDATION each fold ~~~~\")\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    lr = LinearRegression().fit(X.iloc[train_index], y.iloc[train_index])\n",
    "    \n",
    "    mse_values.append(metrics.mean_squared_error(y.iloc[test_index], lr.predict(X.iloc[test_index])))\n",
    "    scores.append(lr.score(X, y))\n",
    "    \n",
    "    n += 1\n",
    "    \n",
    "    print('Model {}'.format(n))\n",
    "    print('MSE: {}'.format(np.mean(np.sqrt(np.absolute(mse_values[n-1])))))\n",
    "    print('R2: {}\\n'.format(scores[n-1]))\n",
    "\n",
    "\n",
    "print(\"~~~~ SUMMARY OF CROSS VALIDATION ~~~~\")\n",
    "print('Mean of MSE for all folds: {}'.format(np.mean(np.sqrt(np.absolute(mse_values)))))\n",
    "print('Mean of R2 for all folds: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.828658946215808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.52991509, 5.10378498, 5.75101191, 8.9867887 , 5.77179405])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "lr = LinearRegression()\n",
    "scores = cross_validate(lr, X, y, scoring='neg_mean_squared_error',cv=5, return_train_score=False)\n",
    "# be attuned to the average error\n",
    "print(np.mean(np.sqrt(abs(scores['test_score']))))\n",
    "np.sqrt(abs(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the cross-validated approach here generated more overall error, which of the two approaches would predict new data more accurately — the single model or the cross-validated, averaged one? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"three-way-data-split\"></a>\n",
    "## Three-Way Data Split\n",
    "---\n",
    "\n",
    "The most common workflow is actually a combination of train/test split and cross-validation. We take a train/test split on our data right away and try not spend a lot of time using the testing data set. Instead, we take our training data and tune our models using cross-validation. When we think we are done, we do one last test on the testing data to make sure we haven't accidently overfit to our training data.\n",
    "\n",
    "**If you tune hyperparameters via cross-validation, you should never use cross-validation on the same dataset to estimate OOS accuracy!** Using cross-validation in this way, the entire dataset was used to tune hyperparameters. So, this invalidates our condition above -- where we assumed the test set is a pretend \"out-of-sample\" dataset that was not used to train our model! So, we would expect the accuracy on this test set to be artificially inflated as compared to actual \"out-of-sample\" data.\n",
    "\n",
    "Even with good evaluation procedures, it is incredible easy to overfit our models by including features that will not be available during production or leak information about our testing data in other ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/Train-Test-Split-CV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- If model selection and true error estimates are to be computed simultaneously, three disjointed data sets are best.\n",
    "    - **Training set**: A set of examples used for learning – what parameters of the classifier?\n",
    "    - **Validation set**: A set of examples used to tune the parameters of the classifier.\n",
    "    - **Testing set**: A set of examples used ONLY to assess the performance of the fully trained classifier.\n",
    "- Validation and testing must be separate data sets. Once you have the final model set, you cannot do any additional tuning after testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Divide data into training, validation, and testing sets.\n",
    "2. Select architecture (model type) and training parameters (k).\n",
    "3. Train the model using the training set.\n",
    "4. Evaluate the model using the training set.\n",
    "5. Repeat 2–4 times, selecting different architectures (models) and tuning parameters.\n",
    "6. Select the best model.\n",
    "7. Assess the model with the final testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"additional-resources\"></a>\n",
    "<a id=\"additional-resources\"></a>\n",
    "### Additional Resources\n",
    "- University of Washington [slides](https://courses.cs.washington.edu/courses/cse546/12wi/slides/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "### Summary\n",
    "\n",
    "In this lab, we compared four methods of estimating model accuracy on out-of-sample data. Throughout your regular data science work, you will likely use all four at some point:\n",
    "\n",
    "1. **Train on the entire dataset**\n",
    "2. **Train-test-split**\n",
    "3. **Cross-validation**\n",
    "4. **Three-way split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
